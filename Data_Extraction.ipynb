{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pymysql\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to get the data's of all states:\n",
    "\n",
    "path = \"D:/PROJECTS/PhonePe/pulse/data/aggregated/transaction/country/india/state\"\n",
    "agg_tr_st_list = os.listdir(path)\n",
    "path_1 = \"D:/PROJECTS/PhonePe/pulse/data/aggregated/user/country/india/state\"\n",
    "agg_ur_st_list = os.listdir(path_1)\n",
    "path_2 =\"D:/PROJECTS/PhonePe/pulse/data/map/transaction/hover/country/india/state\"\n",
    "map_tr_st_list = os.listdir(path_2)\n",
    "path_3 = \"D:/PROJECTS/PhonePe/pulse/data/map/user/hover/country/india/state\"\n",
    "map_ur_st_list = os.listdir(path_3)\n",
    "path_4 = \"D:/PROJECTS/PhonePe/pulse/data/top/transaction/country/india/state\"\n",
    "top_tr_st_list = os.listdir(path_4)\n",
    "path_5 =\"D:/PROJECTS/PhonePe/pulse/data/top/user/country/india/state\"\n",
    "top_ur_st_list = os.listdir(path_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract the Aggregated Transaction Data's to create a dataframe:\n",
    "clm={'State':[], 'Year':[],'Quater':[],'Transaction_type':[], 'Transaction_count':[], 'Transaction_amount':[]}\n",
    "for state in agg_tr_st_list:\n",
    "    agg_tr_year = path +\"/\" + state\n",
    "    agg_tr_yr = os.listdir(agg_tr_year)\n",
    "    for yr in agg_tr_yr:\n",
    "        agg_tr_path = agg_tr_year +\"/\"+ yr\n",
    "        agg_tr_files = os.listdir(agg_tr_path)\n",
    "        for file in agg_tr_files:\n",
    "            tr_fl_path = agg_tr_path +\"/\"+ file\n",
    "            data = open(tr_fl_path,\"r\")\n",
    "            d=json.load(data)\n",
    "            for i in d[\"data\"][\"transactionData\"]:\n",
    "                clm[\"State\"].append(state.title())\n",
    "                clm[\"Year\"].append(yr)\n",
    "                clm[\"Quater\"].append((int(file.strip('.json'))))\n",
    "                clm[\"Transaction_type\"].append(i['name'])\n",
    "                clm[\"Transaction_count\"].append(i[\"paymentInstruments\"][0][\"count\"])\n",
    "                clm[\"Transaction_amount\"].append(i[\"paymentInstruments\"][0][\"amount\"])\n",
    "agg_transaction = pd.DataFrame(clm) #Transaction data broken down by type of payment at country level\n",
    "agg_transaction['State'] = agg_transaction['State'].apply(lambda x: x.replace('-', ' ')\n",
    "                                              .replace (\"Andaman & Nicobar Islands\",\"Andaman & Nicobar\")\n",
    "                                              .replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "                                                  )\n",
    "agg_transaction.to_csv(\"D:/PROJECTS/PhonePe/Tables/Agg_Transaction.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract the Aggregated user data's to create a dataframe:\n",
    "clm1={'State':[], 'Year':[],'Quater':[],'Registered_Users':[], 'App_open_no':[],'Device':[],'Count':[], 'Share_Percentage':[]}\n",
    "for state in agg_ur_st_list:\n",
    "    agg_ur_year = path_1 +\"/\" + state\n",
    "    agg_ur_yr = os.listdir(agg_ur_year)\n",
    "    for yr in agg_ur_yr:\n",
    "        dt_ur_path = agg_ur_year +\"/\"+ yr\n",
    "        ur_files = os.listdir(dt_ur_path)\n",
    "        for file in ur_files:\n",
    "            ur_fl_path = dt_ur_path +\"/\"+ file\n",
    "            data = open(ur_fl_path,\"r\")\n",
    "            d=json.load(data)\n",
    "            Users = d[\"data\"][\"aggregated\"][\"registeredUsers\"]\n",
    "            App_open = d[\"data\"][\"aggregated\"][\"appOpens\"]\n",
    "            if d[\"data\"][\"usersByDevice\"] is not None:\n",
    "                for i in d[\"data\"][\"usersByDevice\"]:\n",
    "                    clm1[\"State\"].append(state.title())\n",
    "                    clm1[\"Year\"].append(yr)\n",
    "                    clm1[\"Quater\"].append((int(file.strip('.json'))))\n",
    "                    clm1[\"Registered_Users\"].append(Users)\n",
    "                    clm1[\"App_open_no\"].append(App_open)\n",
    "                    clm1[\"Device\"].append(i[\"brand\"]) \n",
    "                    clm1[\"Count\"].append(i[\"count\"])\n",
    "                    clm1[\"Share_Percentage\"].append(i[\"percentage\"])\n",
    "agg_user = pd.DataFrame(clm1) #Users data broken down by devices at country level.\n",
    "agg_user['State'] = agg_user['State'].apply(lambda x: x.replace('-', ' ')\n",
    "                                              .replace (\"Andaman & Nicobar Islands\",\"Andaman & Nicobar\")\n",
    "                                              .replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "                                                  )\n",
    "agg_user.to_csv(\"D:/PROJECTS/PhonePe/Tables/Agg_User.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract the Map Transaction data's to create a dataframe:\n",
    "clm2 ={\"State\":[],'Year':[],'Quater':[],\"District\": [],\"No_of_Transaction\":[],\"Total_amount\":[]}\n",
    "for state in map_tr_st_list:\n",
    "    map_tr_year = path_2 +\"/\" + state\n",
    "    map_tr_yr = os.listdir(map_tr_year)\n",
    "    for yr in map_tr_yr:\n",
    "        map_tr_path = map_tr_year +\"/\"+ yr\n",
    "        map_tr_files = os.listdir(map_tr_path)\n",
    "        for file in map_tr_files:\n",
    "            tr_fl_path = map_tr_path +\"/\"+ file\n",
    "            data = open(tr_fl_path,\"r\")\n",
    "            d=json.load(data) \n",
    "            for i in d[\"data\"][\"hoverDataList\"]:\n",
    "                clm2[\"State\"].append(state.title())\n",
    "                clm2[\"Year\"].append(yr)\n",
    "                clm2[\"Quater\"].append((int(file.strip('.json'))))\n",
    "                clm2[\"District\"].append(i[\"name\"].title())\n",
    "                clm2[\"No_of_Transaction\"].append(i[\"metric\"][0][\"count\"])\n",
    "                clm2[\"Total_amount\"].append(i[\"metric\"][0][\"amount\"])\n",
    "map_transaction = pd.DataFrame(clm2) #Total number of transactions and total value of all transactions at the state level.\n",
    "map_transaction['State'] = map_transaction['State'].apply(lambda x: x.replace('-', ' ')\n",
    "                                              .replace (\"Andaman & Nicobar Islands\",\"Andaman & Nicobar\")\n",
    "                                              .replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "                                                  )\n",
    "map_transaction.to_csv(\"D:/PROJECTS/PhonePe/Tables/Map_Transaction.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract the Map User data's to create a dataframe:\n",
    "clm3 ={\"State\":[],'Year':[],'Quater':[],\"District\": [],\"Registered_Users\":[],\"App_open_no\":[]}\n",
    "for state in map_tr_st_list:\n",
    "    map_ur_year = path_3 +\"/\" + state\n",
    "    map_ur_yr = os.listdir(map_ur_year)\n",
    "    for yr in map_ur_yr:\n",
    "        map_ur_path = map_ur_year +\"/\"+ yr\n",
    "        map_ur_files = os.listdir(map_ur_path)\n",
    "        for file in map_ur_files:\n",
    "            ur_fl_path = map_ur_path +\"/\"+ file\n",
    "            data = open(ur_fl_path,\"r\")\n",
    "            d=json.load(data) \n",
    "            for district,values in d[\"data\"][\"hoverData\"].items():\n",
    "                clm3[\"State\"].append(state.title())\n",
    "                clm3[\"Year\"].append(yr)\n",
    "                clm3[\"Quater\"].append((int(file.strip('.json'))))\n",
    "                clm3[\"District\"].append(district.title())\n",
    "                clm3[\"Registered_Users\"].append(values['registeredUsers'])\n",
    "                clm3[\"App_open_no\"].append(values['appOpens'])\n",
    "map_user = pd.DataFrame(clm3)#Total number of registered users and number of app opens by these registered users at the state level.\n",
    "map_user['State'] = map_user['State'].apply(lambda x: x.replace('-', ' ')\n",
    "                                              .replace (\"Andaman & Nicobar Islands\",\"Andaman & Nicobar\")\n",
    "                                              .replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "                                                  )\n",
    "map_user.to_csv(\"D:/PROJECTS/PhonePe/Tables/Map_User.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract the Top Transaction data's to create a dataframe:\n",
    "clm4 = {\"State\":[], 'Year':[],'Quater':[],\"Pincode\":[], \"Total_No_Of_Transactions\":[], \"Total_Amount\":[]}\n",
    "for state in top_tr_st_list:\n",
    "    top_tr_year = path_4 +\"/\" + state\n",
    "    top_tr_yr = os.listdir(top_tr_year)\n",
    "    for yr in top_tr_yr:\n",
    "        top_tr_path = top_tr_year +\"/\"+ yr\n",
    "        top_tr_files = os.listdir(top_tr_path)\n",
    "        for file in top_tr_files:\n",
    "            tr_fl_path = top_tr_path +\"/\"+ file\n",
    "            data = open(tr_fl_path,\"r\")\n",
    "            d=json.load(data) \n",
    "            for i in d[\"data\"][\"pincodes\"]:\n",
    "                clm4[\"State\"].append(state.title())\n",
    "                clm4[\"Year\"].append(yr)\n",
    "                clm4[\"Quater\"].append((int(file.strip('.json'))))\n",
    "                clm4[\"Pincode\"].append(i[\"entityName\"])\n",
    "                clm4[\"Total_No_Of_Transactions\"].append(i[\"metric\"][\"count\"])\n",
    "                clm4[\"Total_Amount\"].append(i[\"metric\"][\"amount\"])\n",
    "top_transaction=pd.DataFrame(clm4) #Top 10 states / districts where the most number of the transactions happened for a selected year-quarter combination.\n",
    "top_transaction['State'] = top_transaction['State'].apply(lambda x: x.replace('-', ' ')\n",
    "                                              .replace (\"Andaman & Nicobar Islands\",\"Andaman & Nicobar\")\n",
    "                                              .replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "                                                  )\n",
    "top_transaction.to_csv(\"D:/PROJECTS/PhonePe/Tables/Top_Transaction.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract the Top District User data's to create a dataframe:\n",
    "clm6 ={\"State\":[], 'Year':[],'Quater':[],\"Districts\":[],\"Users\":[]}\n",
    "for state in top_ur_st_list:\n",
    "    top_ur_year = path_5 +\"/\" + state\n",
    "    top_ur_yr = os.listdir(top_ur_year)\n",
    "    for yr in top_ur_yr:\n",
    "        top_ur_path = top_ur_year +\"/\"+ yr\n",
    "        top_ur_files = os.listdir(top_ur_path)\n",
    "        for file in top_ur_files:\n",
    "            ur_fl_path = top_ur_path +\"/\"+ file\n",
    "            data = open(ur_fl_path,\"r\")\n",
    "            d=json.load(data)\n",
    "            for i in d[\"data\"][\"districts\"]:\n",
    "                clm6[\"State\"].append(state.title())\n",
    "                clm6[\"Year\"].append(yr)\n",
    "                clm6[\"Quater\"].append((int(file.strip('.json'))))\n",
    "                clm6[\"Districts\"].append(i[\"name\"].title())\n",
    "                clm6[\"Users\"].append(i[\"registeredUsers\"])\n",
    "top_users = pd.DataFrame(clm6)\n",
    "top_users['State'] = top_users['State'].apply(lambda x: x.replace('-', ' ')\n",
    "                                              .replace (\"Andaman & Nicobar Islands\",\"Andaman & Nicobar\")\n",
    "                                              .replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "                                                  )\n",
    "top_users.to_csv(\"D:/PROJECTS/PhonePe/Tables/Top_Users.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract the Top User Pincode data's to create a dataframe:\n",
    "clm7 ={\"State\":[], 'Year':[],'Quater':[],\"Pincode\":[],\"Users\":[]}\n",
    "for state in top_ur_st_list:\n",
    "    top_ur_year = path_5 +\"/\" + state\n",
    "    top_ur_yr = os.listdir(top_ur_year)\n",
    "    for yr in top_ur_yr:\n",
    "        top_ur_path = top_ur_year +\"/\"+ yr\n",
    "        top_ur_files = os.listdir(top_ur_path)\n",
    "        for file in top_ur_files:\n",
    "            ur_fl_path = top_ur_path +\"/\"+ file\n",
    "            data = open(ur_fl_path,\"r\")\n",
    "            d=json.load(data)\n",
    "            for i in d[\"data\"][\"pincodes\"]:\n",
    "                    clm7[\"State\"].append(state.title())\n",
    "                    clm7[\"Year\"].append(yr)\n",
    "                    clm7[\"Quater\"].append((int(file.strip('.json'))))\n",
    "                    clm7[\"Pincode\"].append(i[\"name\"])\n",
    "                    clm7[\"Users\"].append(i[\"registeredUsers\"])\n",
    "Top_ur_PinCode = pd.DataFrame(clm7)#Top 10  pin codes where the most number of the transactions happened for a selected year-quarter combination.\n",
    "Top_ur_PinCode['State'] = Top_ur_PinCode['State'].apply(lambda x: x.replace('-', ' ')\n",
    "                                              .replace (\"Andaman & Nicobar Islands\",\"Andaman & Nicobar\")\n",
    "                                              .replace(\"Dadra & Nagar Haveli & Daman & Diu\", \"Dadra and Nagar Haveli and Daman and Diu\")\n",
    "                                                  )\n",
    "Top_ur_PinCode.to_csv(\"D:/PROJECTS/PhonePe/Tables/Top_ur_PinCode.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(value):\n",
    "    percentage_values = [round(value * 100, 2)]\n",
    "    return percentage_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL connection\n",
    "mysql_connection  =  pymysql.connect(host = \"127.0.0.1\",\n",
    "                                user='root',\n",
    "                                passwd='Nisha@130899',\n",
    "                                database =\"PhonePe\",\n",
    "                                autocommit=True)                                \n",
    "mysql_cursor  = mysql_connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''use PhonePe'''\n",
    "mysql_cursor.execute(query)\n",
    "mysql_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table creation - Aggregated_Transaction_Data:\n",
    "create_query ='''CREATE TABLE IF NOT EXISTS Aggregated_Transaction_Data(\n",
    "                                            State varchar(150),\n",
    "                                            Year int,\n",
    "                                            Quater int,\n",
    "                                            Transaction_type varchar(200),\n",
    "                                            Transaction_count bigint,\n",
    "                                            Transaction_amount bigint   )''' \n",
    "mysql_cursor.execute(create_query)\n",
    "mysql_connection.commit()\n",
    "# Insert Dataframe into SQL Server:\n",
    "file_path = \"D:/PROJECTS/PhonePe/Tables/Agg_Transaction.csv\"\n",
    "agg_transaction = pd.read_csv(file_path)\n",
    "for index, row in agg_transaction.iterrows():\n",
    "    \n",
    "    mysql_cursor.execute('''\n",
    "                    INSERT INTO Aggregated_Transaction_Data(\n",
    "                                            State,\n",
    "                                            Year,\n",
    "                                            Quater,\n",
    "                                            Transaction_type,\n",
    "                                            Transaction_count,\n",
    "                                            Transaction_amount   \n",
    "                    )\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                    ''',(\n",
    "                        row.State,\n",
    "                        row.Year,\n",
    "                        row.Quater,\n",
    "                        row.Transaction_type ,\n",
    "                        row.Transaction_count,\n",
    "                        row.Transaction_amount,\n",
    "                    ))\n",
    "mysql_connection.commit()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table creation - Aggregated_User_Data:\n",
    "create_query ='''CREATE TABLE IF NOT EXISTS Aggregated_User_Data(\n",
    "                                            State varchar(150),\n",
    "                                            Year int,\n",
    "                                            Quater int,\n",
    "                                            Registered_Users bigint,\n",
    "                                            App_open_no bigint,\n",
    "                                            Device text,\n",
    "                                            Count bigint,\n",
    "                                            Share_Percentage text)''' \n",
    "mysql_cursor.execute(create_query)\n",
    "mysql_connection.commit()\n",
    "# Insert Dataframe into SQL Server:\n",
    "file_path = \"D:/PROJECTS/PhonePe/Tables/Agg_User.csv\"\n",
    "agg_user = pd.read_csv(file_path)\n",
    "for index, row in agg_user.iterrows():\n",
    "    percentage_value = percentage(row.Share_Percentage)\n",
    "    mysql_cursor.execute('''\n",
    "                    INSERT INTO Aggregated_User_Data(\n",
    "                                            State,\n",
    "                                            Year,\n",
    "                                            Quater,\n",
    "                                            Registered_Users,\n",
    "                                            App_open_no,\n",
    "                                            Device,\n",
    "                                            Count,\n",
    "                                            Share_Percentage\n",
    "                    )\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s , %s, CONCAT(%s, '%%'))\n",
    "                    ''',(\n",
    "                        row.State,\n",
    "                        row.Year,\n",
    "                        row.Quater,\n",
    "                        row.Registered_Users ,\n",
    "                        row.App_open_no,\n",
    "                        row.Device,\n",
    "                        row.Count,\n",
    "                        percentage_value\n",
    "                    ))\n",
    "mysql_connection.commit() \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table creation - Map_Transaction_data:\n",
    "create_query ='''CREATE TABLE IF NOT EXISTS Map_Transaction_Data(\n",
    "                                            State varchar(150),\n",
    "                                            Year int,\n",
    "                                            Quater int,\n",
    "                                            District varchar(200),\n",
    "                                            No_of_Transaction bigint,\n",
    "                                            Total_amount bigint   )''' \n",
    "mysql_cursor.execute(create_query)\n",
    "mysql_connection.commit()\n",
    "# Insert Dataframe into SQL Server:\n",
    "file_path = \"D:/PROJECTS/PhonePe/Tables/Map_Transaction.csv\"\n",
    "map_transaction = pd.read_csv(file_path)\n",
    "for index, row in map_transaction.iterrows():\n",
    "    mysql_cursor.execute('''\n",
    "                    INSERT INTO Map_Transaction_Data(\n",
    "                                            State,\n",
    "                                            Year,\n",
    "                                            Quater,\n",
    "                                            District,\n",
    "                                            No_of_Transaction,\n",
    "                                            Total_amount   \n",
    "                    )\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                    ''',(\n",
    "                        row.State,\n",
    "                        row.Year,\n",
    "                        row.Quater,\n",
    "                        row.District ,\n",
    "                        row.No_of_Transaction,\n",
    "                        row.Total_amount,\n",
    "                    ))\n",
    "mysql_connection.commit()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table creation - Map_User_Data:\n",
    "create_query ='''CREATE TABLE IF NOT EXISTS Map_User_Data(\n",
    "                                            State varchar(150),\n",
    "                                            Year int,\n",
    "                                            Quater int,\n",
    "                                            District varchar(200),\n",
    "                                            Registered_Users bigint,\n",
    "                                            App_open_no bigint\n",
    "                                            )''' \n",
    "mysql_cursor.execute(create_query)\n",
    "mysql_connection.commit()\n",
    "# Insert Dataframe into SQL Server:\n",
    "file_path = \"D:/PROJECTS/PhonePe/Tables/Map_User.csv\"\n",
    "map_user = pd.read_csv(file_path)\n",
    "for index, row in map_user.iterrows():\n",
    "    mysql_cursor.execute('''\n",
    "                    INSERT INTO Map_User_Data(\n",
    "                                            State,\n",
    "                                            Year,\n",
    "                                            Quater,\n",
    "                                            District,\n",
    "                                            Registered_Users,\n",
    "                                            App_open_no\n",
    "                                            \n",
    "                    )\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                    ''',(\n",
    "                        row.State,\n",
    "                        row.Year,\n",
    "                        row.Quater,\n",
    "                        row.District ,\n",
    "                        row.Registered_Users,\n",
    "                        row.App_open_no\n",
    "                    ))\n",
    "mysql_connection.commit() \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table creation - Top_Transaction_data:\n",
    "\n",
    "create_query ='''CREATE TABLE IF NOT EXISTS Top_Transaction_data(\n",
    "                                            State varchar(150),\n",
    "                                            Year int,\n",
    "                                            Quater int,\n",
    "                                            Pincode varchar(200),\n",
    "                                            Total_No_Of_Transactions bigint,\n",
    "                                            Total_Amount bigint   )''' \n",
    "mysql_cursor.execute(create_query)\n",
    "mysql_connection.commit()\n",
    "# Insert Dataframe into SQL Server:\n",
    "file_path = \"D:/PROJECTS/PhonePe/Tables/Top_Transaction.csv\"\n",
    "top_transaction = pd.read_csv(file_path)\n",
    "top_transaction.fillna(0, inplace=True)\n",
    "for index, row in top_transaction.iterrows():\n",
    "    mysql_cursor.execute('''\n",
    "                    INSERT INTO Top_Transaction_data(\n",
    "                                            State,\n",
    "                                            Year,\n",
    "                                            Quater,\n",
    "                                            Pincode,\n",
    "                                            Total_No_Of_Transactions,\n",
    "                                            Total_Amount   \n",
    "                    )\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                    ''',(\n",
    "                        row.State,\n",
    "                        row.Year,\n",
    "                        row.Quater,\n",
    "                        row.Pincode ,\n",
    "                        row.Total_No_Of_Transactions,\n",
    "                        row.Total_Amount,\n",
    "                    ))\n",
    "mysql_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table creation - Top_User_data:\n",
    "\n",
    "create_query ='''CREATE TABLE IF NOT EXISTS Top_User_data(\n",
    "                                            State varchar(150),\n",
    "                                            Year int,\n",
    "                                            Quater int,\n",
    "                                            Districts varchar(200),\n",
    "                                            Users bigint\n",
    "                                            )''' \n",
    "mysql_cursor.execute(create_query)\n",
    "mysql_connection.commit()\n",
    "# Insert Dataframe into SQL Server:\n",
    "file_path = \"D:/PROJECTS/PhonePe/Tables/Top_Users.csv\"\n",
    "top_users = pd.read_csv(file_path)\n",
    "for index, row in top_users.iterrows():\n",
    "    mysql_cursor.execute('''\n",
    "                    INSERT INTO Top_User_data(\n",
    "                                            State,\n",
    "                                            Year,\n",
    "                                            Quater,\n",
    "                                            Districts,\n",
    "                                            Users                                              \n",
    "                                            )\n",
    "                    VALUES (%s, %s, %s, %s, %s)\n",
    "                    ''',(\n",
    "                        row.State,\n",
    "                        row.Year,\n",
    "                        row.Quater,\n",
    "                        row.Districts ,\n",
    "                        row.Users\n",
    "                    ))\n",
    "mysql_connection.commit()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table creation - Top_Ur_Pincode_data:\n",
    "\n",
    "create_query ='''CREATE TABLE IF NOT EXISTS Top_Ur_Pincode_data(\n",
    "                                            State varchar(150),\n",
    "                                            Year int,\n",
    "                                            Quater int,\n",
    "                                            Pincode int,\n",
    "                                            Users bigint\n",
    "                                                  )''' \n",
    "mysql_cursor.execute(create_query)\n",
    "mysql_connection.commit()\n",
    "# Insert Dataframe into SQL Server:\n",
    "file_path = \"D:/PROJECTS/PhonePe/Tables/Top_ur_PinCode.csv\"\n",
    "Top_ur_PinCode = pd.read_csv(file_path)\n",
    "for index, row in Top_ur_PinCode.iterrows():\n",
    "    mysql_cursor.execute('''\n",
    "                    INSERT INTO Top_Ur_Pincode_data(\n",
    "                                            State,\n",
    "                                            Year,\n",
    "                                            Quater,\n",
    "                                            Pincode,\n",
    "                                            Users  \n",
    "                    )\n",
    "                    VALUES (%s, %s, %s, %s, %s)\n",
    "                    ''',(\n",
    "                        row.State,\n",
    "                        row.Year,\n",
    "                        row.Quater,\n",
    "                        row.Pincode ,\n",
    "                        row.Users\n",
    "                    ))\n",
    "mysql_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
